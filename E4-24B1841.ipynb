{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_v0 = pd.read_csv('Clusters-4-v0.csv')\n",
    "data_v1 = pd.read_csv('Clusters-4-v1.csv')\n",
    "data_v2 = pd.read_csv('Clusters-4-v2.csv')\n",
    "\n",
    "x_train_v0, x_test_v0, y_train_v0, y_test_v0 = train_test_split(data_v0[['x1', 'x2']], data_v0['y'], test_size=0.2, random_state=62, stratify = data_v0['y'])\n",
    "x_train_v1, x_test_v1, y_train_v1, y_test_v1 = train_test_split(data_v1[['x1', 'x2']], data_v1['y'], test_size=0.2, random_state=82, stratify = data_v1['y'])\n",
    "x_train_v2, x_test_v2, y_train_v2, y_test_v2 = train_test_split(data_v2[['x1', 'x2']], data_v2['y'], test_size=0.2, random_state=92, stratify = data_v2['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_relation(df):\n",
    "    colors = {1: 'red', 2: 'blue', 3: 'green', 4: 'orange'}\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "\n",
    "    for cls in df['y'].unique():\n",
    "        subset = df[df['y'] == cls]\n",
    "        plt.scatter(subset['x1'], subset['x2'], c=colors[cls], label=f'Class {cls}', alpha=0.7, edgecolors='k')\n",
    "\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Scatter plot of x1 vs x2 by class')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relation(data_v0)\n",
    "plot_relation(data_v1)\n",
    "plot_relation(data_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "algorithms = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=5000),\n",
    "    'Logistic Regression + Poly(2)': Pipeline([('poly', PolynomialFeatures(degree=2)),('logreg', LogisticRegression(max_iter=10000))]),\n",
    "    'SVC (linear)': SVC(kernel='linear', probability=True),\n",
    "    'SVC (rbf)': SVC(kernel='rbf', probability=True),\n",
    "    'NeuralNet (5)': MLPClassifier(hidden_layer_sizes=(5,), max_iter=5000),\n",
    "    'NeuralNet (5,5)': MLPClassifier(hidden_layer_sizes=(5,5), max_iter=5000),\n",
    "    'NeuralNet (5,5,5)': MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=5000),\n",
    "    'NeuralNet (10)': MLPClassifier(hidden_layer_sizes=(10,), max_iter=5000),\n",
    "}\n",
    "\n",
    "for depth in range(2, 6):\n",
    "    for leaf in range(1, 6):\n",
    "        name = f'RandomForest d{depth}_l{leaf}'\n",
    "        algorithms[name] = RandomForestClassifier(max_depth=depth, min_samples_leaf=leaf)\n",
    "\n",
    "\n",
    "metric_table_train_v0 = pd.DataFrame()\n",
    "metric_table_test_v0 = pd.DataFrame()\n",
    "metric_table_train_v1 = pd.DataFrame()\n",
    "metric_table_test_v1 = pd.DataFrame()\n",
    "metric_table_train_v2 = pd.DataFrame()\n",
    "metric_table_test_v2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def helperFunction(classes, statistic, metric_table_train, metric_table_test, algorithm_name, data1, data2):\n",
    "    i = 0\n",
    "    while i < len(classes):\n",
    "        c = classes[i]\n",
    "        metric_table_train.at[algorithm_name, f'{statistic}_{c}'] = data1[i]\n",
    "\n",
    "        metric_table_test.at[algorithm_name, f'{statistic}_{c}'] = data2[i]\n",
    "        i += 1\n",
    "\n",
    "def run_classification_metrics_plot(X_train, X_test, y_train, y_test, algorithms, metric_table_train, metric_table_test, version):\n",
    "    classes = sorted(y_train.unique())\n",
    "    \n",
    "    # fig, axs = plt.subplots(len(algorithms), 2, figsize=(20, 5 * len(algorithms)))\n",
    "    # fig_row = -1\n",
    "\n",
    "    for algorithm_name, algorithm in algorithms.items():\n",
    "\n",
    "        algorithm.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = algorithm.predict(X_train)\n",
    "        y_test_pred = algorithm.predict(X_test)\n",
    "\n",
    "        # Got an error because, SVC didnt support probabilities on its own, so this bit was needed to make my code run properly. Other models will work ok, but SVC requires the else block.\n",
    "        if hasattr(algorithm, \"predict_proba\"):\n",
    "            y_train_proba = algorithm.predict_proba(X_train)\n",
    "            y_test_proba = algorithm.predict_proba(X_test)\n",
    "        else:\n",
    "            class_to_index = {c: i for i, c in enumerate(classes)}\n",
    "            \n",
    "            y_train_idx = np.array([class_to_index[y] for y in y_train_pred])\n",
    "            y_test_idx  = np.array([class_to_index[y] for y in y_test_pred])\n",
    "            \n",
    "            y_train_proba = np.eye(len(classes))[y_train_idx]\n",
    "            y_test_proba  = np.eye(len(classes))[y_test_idx]\n",
    "\n",
    "\n",
    "        acc_train = accuracy_score(y_train, y_train_pred)\n",
    "        prec_train = precision_score(y_train, y_train_pred, average=None, labels=classes, zero_division=0)\n",
    "        rec_train = recall_score(y_train, y_train_pred, average=None, labels=classes, zero_division=0)\n",
    "        f1_train = f1_score(y_train, y_train_pred, average=None, labels=classes, zero_division=0)\n",
    "        auc_train = roc_auc_score(y_train, y_train_proba, average=None, multi_class='ovr')\n",
    "\n",
    "        prec_avg_train = precision_score(y_train, y_train_pred, average=\"weighted\", zero_division=0)\n",
    "        rec_avg_train = recall_score(y_train, y_train_pred, average=\"weighted\", zero_division=0)\n",
    "        f1_avg_train = f1_score(y_train, y_train_pred, average=\"weighted\", zero_division=0)\n",
    "        auc_avg_train = roc_auc_score(y_train, y_train_proba, average=\"weighted\", multi_class='ovr')\n",
    "\n",
    "\n",
    "        acc_test = accuracy_score(y_test, y_test_pred)\n",
    "        prec_test = precision_score(y_test, y_test_pred, average=None, labels=classes, zero_division=0)\n",
    "        rec_test = recall_score(y_test, y_test_pred, average=None, labels=classes, zero_division=0)\n",
    "        f1_test = f1_score(y_test, y_test_pred, average=None, labels=classes, zero_division=0)\n",
    "        auc_test = roc_auc_score(y_test, y_test_proba, average=None, multi_class='ovr')\n",
    "\n",
    "        prec_avg_test = precision_score(y_test, y_test_pred, average=\"weighted\", zero_division=0)\n",
    "        rec_avg_test = recall_score(y_test, y_test_pred, average=\"weighted\", zero_division=0)\n",
    "        f1_avg_test = f1_score(y_test, y_test_pred, average=\"weighted\", zero_division=0)\n",
    "        auc_avg_test = roc_auc_score(y_test, y_test_proba, average=\"weighted\", multi_class='ovr')\n",
    "\n",
    "\n",
    "        metric_table_train.at[algorithm_name, 'Accuracy'] = acc_train\n",
    "        metric_table_test.at[algorithm_name, 'Accuracy'] = acc_test\n",
    "\n",
    "        metric_table_train.at[algorithm_name, 'Precision_avg'] = prec_avg_train\n",
    "        metric_table_test.at[algorithm_name, 'Precision_avg'] = prec_avg_test\n",
    "        helperFunction(classes, \"Precision\", metric_table_train, metric_table_test, algorithm_name, prec_train, prec_test)\n",
    "\n",
    "        metric_table_train.at[algorithm_name, 'Recall_avg'] = rec_avg_train\n",
    "        metric_table_test.at[algorithm_name, 'Recall_avg'] = rec_avg_test\n",
    "        helperFunction(classes, \"Recall\", metric_table_train, metric_table_test, algorithm_name, rec_train, rec_test)\n",
    "\n",
    "        metric_table_train.at[algorithm_name, 'F1_avg'] = f1_avg_train\n",
    "        metric_table_test.at[algorithm_name, 'F1_avg'] = f1_avg_test\n",
    "        helperFunction(classes, \"F1\", metric_table_train, metric_table_test, algorithm_name, f1_train, f1_test)\n",
    "\n",
    "        metric_table_train.at[algorithm_name, 'AUC_avg'] = auc_avg_train\n",
    "        metric_table_test.at[algorithm_name, 'AUC_avg'] = auc_avg_test\n",
    "        helperFunction(classes, \"AUC\", metric_table_train, metric_table_test, algorithm_name, auc_train, auc_test)\n",
    "\n",
    "        # fig_row += 1\n",
    "        cm_train = confusion_matrix(y_train, y_train_pred, labels=classes)\n",
    "        cm_test = confusion_matrix(y_test, y_test_pred, labels=classes)\n",
    "\n",
    "        # axs[fig_row, 0].imshow(cm_train, cmap='Blues')\n",
    "        # axs[fig_row, 0].set_title(algorithm_name + \" - Train\")\n",
    "        # for i in range(len(classes)):\n",
    "        #     for j in range(len(classes)):\n",
    "        #         axs[fig_row, 0].text(j, i, cm_train[i, j], ha='center', va='center', color='red')\n",
    "\n",
    "        # axs[fig_row, 1].imshow(cm_test, cmap='Greens')\n",
    "        # axs[fig_row, 1].set_title(algorithm_name + \" - Test\")\n",
    "        # for i in range(len(classes)):\n",
    "        #     for j in range(len(classes)):\n",
    "        #         axs[fig_row, 1].text(j, i, cm_test[i, j], ha='center', va='center', color='red')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    metric_table_train.to_csv(f\"metrics_train_v{version}.csv\")\n",
    "    metric_table_test.to_csv(f\"metrics_test_v{version}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_model_results_row(X_train, X_test, y_train, y_test, algorithms):\n",
    "    classes = np.unique(np.concatenate([y_train, y_test]))\n",
    "    y_train_bin = label_binarize(y_train, classes=classes)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    \n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    for algorithm_name, algorithm in algorithms.items():\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "        fig.suptitle(algorithm_name, fontsize=14, fontweight=\"bold\")\n",
    "        \n",
    "        if X_train.shape[1] == 2:\n",
    "            ax = axes[0]\n",
    "            h = 0.08\n",
    "            x_min, x_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "            y_min, y_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            \n",
    "            mesh_points = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=feature_names)\n",
    "            Z = algorithm.predict(mesh_points)\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "            ax.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train, edgecolor=\"k\", cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "            ax.set_title(\"Decision Boundary (Train)\")\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, \"Decision boundary\", ha='center')\n",
    "        \n",
    "        if X_train.shape[1] == 2:\n",
    "            ax = axes[1]\n",
    "            h = 0.08\n",
    "            x_min, x_max = X_test.iloc[:, 0].min() - 1, X_test.iloc[:, 0].max() + 1\n",
    "            y_min, y_max = X_test.iloc[:, 1].min() - 1, X_test.iloc[:, 1].max() + 1\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            \n",
    "            mesh_points = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=feature_names)\n",
    "            Z = algorithm.predict(mesh_points)\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "            ax.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c=y_test, edgecolor=\"k\", cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "            ax.set_title(\"Decision Boundary (Test)\")\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, \"Decision boundary\", ha='center')\n",
    "        \n",
    "        ax = axes[2]\n",
    "        for i, cls in enumerate(classes):\n",
    "            y_score = algorithm.predict_proba(X_train)[:, i]\n",
    "            fpr, tpr, _ = roc_curve(y_train_bin[:, i], y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, label=f\"Class {cls} (AUC={roc_auc:.2f})\")\n",
    "        ax.plot([0, 1], [0, 1], \"k--\")\n",
    "        ax.set_title(\"ROC Curve (Train)\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        \n",
    "        ax = axes[3]\n",
    "        for i, cls in enumerate(classes):\n",
    "            y_score = algorithm.predict_proba(X_test)[:, i]\n",
    "            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, label=f\"Class {cls} (AUC={roc_auc:.2f})\")\n",
    "        ax.plot([0, 1], [0, 1], \"k--\")\n",
    "        ax.set_title(\"ROC Curve (Test)\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"Metrics for DataSet-v0\")\n",
    "run_classification_metrics_plot(x_train_v0, x_test_v0, y_train_v0, y_test_v0, algorithms, metric_table_train_v0, metric_table_test_v0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results_row(x_train_v0, x_test_v0, y_train_v0, y_test_v0, algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"Metrics for DataSet-v1\")\n",
    "run_classification_metrics_plot(x_train_v1, x_test_v1, y_train_v1, y_test_v1, algorithms, metric_table_train_v1, metric_table_test_v1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results_row(x_train_v1, x_test_v1, y_train_v1, y_test_v1, algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4051998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"Metrics for DataSet-v2\")\n",
    "run_classification_metrics_plot(x_train_v2, x_test_v2, y_train_v2, y_test_v2, algorithms, metric_table_train_v2, metric_table_test_v2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results_row(x_train_v2, x_test_v2, y_train_v2, y_test_v2, algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ed97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "def run_clustering(X, dataset_name, n_clusters):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    algorithms_clustering = {\"KMeans\": KMeans(n_clusters, random_state=42)}\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    for link in linkages:\n",
    "        name = f\"Hierarchical-{link}\"\n",
    "        algorithms_clustering[name] = AgglomerativeClustering(n_clusters, linkage=link)\n",
    "    \n",
    "    results = []\n",
    "    for name, algo in algorithms_clustering.items():\n",
    "        labels = algo.fit_predict(X)\n",
    "        sil = silhouette_score(X, labels)\n",
    "        ch = calinski_harabasz_score(X, labels)\n",
    "        db = davies_bouldin_score(X, labels)\n",
    "        results.append({\n",
    "            \"Algorithm\": name,\n",
    "            \"Silhouette\": sil,\n",
    "            \"Calinski-Harabasz\": ch,\n",
    "            \"Davies-Bouldin\": db\n",
    "        })\n",
    "    \n",
    "    metric_table = pd.DataFrame(results)\n",
    "    print(metric_table)\n",
    "    \n",
    "    kmeans_labels = algorithms_clustering[\"KMeans\"].fit_predict(X)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(X[:,0], X[:,1], c=kmeans_labels, cmap='viridis', s=50, edgecolor='k')\n",
    "    plt.title(f\"KMeans Clusters ({dataset_name})\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "    \n",
    "    for link in linkages:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sch.dendrogram(sch.linkage(X, method=link))\n",
    "        plt.title(f\"Hierarchical Clustering Dendrogram ({link} linkage) - {dataset_name}\")\n",
    "        plt.xlabel(\"Sample index\")\n",
    "        plt.ylabel(\"Distance\")\n",
    "        plt.show()\n",
    "    \n",
    "    return metric_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v0 = pd.DataFrame()\n",
    "metric_table_cluster_v0 = run_clustering(data_v0[['x1', 'x2']], \"DataSet:v0\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v0 = pd.DataFrame()\n",
    "metric_table_cluster_v0 = run_clustering(data_v0[['x1', 'x2']], \"DataSet:v0\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v0 = pd.DataFrame()\n",
    "metric_table_cluster_v0 = run_clustering(data_v0[['x1', 'x2']], \"DataSet:v0\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v1 = pd.DataFrame()\n",
    "metric_table_cluster_v1 = run_clustering(data_v1[['x1', 'x2']], \"DataSet:v1\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v1 = pd.DataFrame()\n",
    "metric_table_cluster_v1 = run_clustering(data_v1[['x1', 'x2']], \"DataSet:v1\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v1 = pd.DataFrame()\n",
    "metric_table_cluster_v1 = run_clustering(data_v1[['x1', 'x2']], \"DataSet:v1\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v2 = pd.DataFrame()\n",
    "metric_table_cluster_v2 = run_clustering(data_v2[['x1', 'x2']], \"DataSet:v2\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v2 = pd.DataFrame()\n",
    "metric_table_cluster_v2 = run_clustering(data_v2[['x1', 'x2']], \"DataSet:v2\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table_cluster_v2 = pd.DataFrame()\n",
    "metric_table_cluster_v2 = run_clustering(data_v2[['x1', 'x2']], \"DataSet:v2\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
